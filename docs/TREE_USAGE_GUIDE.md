# Complete Guide: Using Trained Trees for Classification

Once you've trained a theta sketch decision tree, you have **6 different ways** to use it for classification. This guide covers all methods with examples.

## üéØ **Overview of Usage Methods**

| Method | Format | Use Case | Performance | Portability |
|--------|--------|----------|-------------|-------------|
| **1. Direct Python** | `.pkl` file | Python production systems | ‚ö° Fastest | üêç Python only |
| **2. JSON Reconstruction** | `.json` file | Python with tree inspection | üîÑ Medium | üêç Python only |
| **3. Generated Rules** | Code files | Cross-platform deployment | ‚ö° Very Fast | üåê Universal |
| **4. SQL Rules** | `.sql` file | Database/warehouse systems | üíæ DB-speed | üóÑÔ∏è Any SQL DB |
| **5. REST API** | HTTP service | Microservice architecture | üåê Network-bound | üîó Any language |
| **6. ONNX Export** | `.onnx` file | ML deployment platforms | ‚ö° Optimized | üîÑ Cross-platform |

---

## **Method 1: Direct Python Usage** üêç

### **Best For**: Python production systems, highest performance
### **Format**: Pickle (.pkl) files

```python
from theta_sketch_tree import ThetaSketchDecisionTreeClassifier
import numpy as np

# Load trained model
clf = ThetaSketchDecisionTreeClassifier.load_model('my_model.pkl')

# Prepare test data (binary features: 0/1 values)
X_test = np.array([
    [1, 0, 1, 0, 1],  # Sample 1
    [0, 1, 0, 1, 0],  # Sample 2
    [1, 1, 0, 0, 1]   # Sample 3
])

# Make predictions
predictions = clf.predict(X_test)
probabilities = clf.predict_proba(X_test)

print(f"Predictions: {predictions}")
print(f"Probabilities: {probabilities}")
print(f"Feature importance: {clf.feature_importances_[:5]}")
```

### **Advantages**:
- ‚ö° **Fastest performance** (~400K predictions/sec)
- üß† **Full model capabilities** (feature importance, tree inspection)
- üîß **Easy integration** with existing Python ML pipelines

### **Limitations**:
- üêç **Python-only** (can't use in Java/C++ systems)
- üì¶ **Requires dependencies** (numpy, scipy, etc.)

---

## **Method 2: JSON Tree Reconstruction** üìÑ

### **Best For**: Python systems needing tree inspection/modification
### **Format**: JSON (.json) files

```python
import json
import numpy as np
from tools.comparison.compare_trees_by_lg_k import json_to_tree_node
from theta_sketch_tree import ThetaSketchDecisionTreeClassifier

# Load tree from JSON
with open('my_model.json', 'r') as f:
    model_data = json.load(f)

# Reconstruct tree structure
tree_root = json_to_tree_node(model_data['tree_structure'])

# Create classifier with reconstructed tree
clf = ThetaSketchDecisionTreeClassifier()
clf.tree_ = tree_root
clf.classes_ = np.array(model_data['classes_'])
clf.feature_names_in_ = np.array(model_data['feature_names'])
clf.n_features_in_ = len(model_data['feature_names'])
clf._is_fitted = True

# Now use normally
predictions = clf.predict(X_test)

# BONUS: Inspect/modify tree structure
def print_tree_rules(node, depth=0):
    indent = "  " * depth
    if node.is_leaf:
        print(f"{indent}PREDICT: {node.prediction} (conf: {node.probabilities[1]:.3f})")
    else:
        print(f"{indent}IF {node.feature_name} == 0:")
        print_tree_rules(node.left, depth + 1)
        print(f"{indent}ELSE IF {node.feature_name} == 1:")
        print_tree_rules(node.right, depth + 1)

print_tree_rules(clf.tree_)
```

### **Advantages**:
- üîç **Tree inspection** - examine exact decision logic
- ‚úèÔ∏è **Tree modification** - programmatically edit rules
- üìä **Debugging** - trace prediction paths
- üóÇÔ∏è **Human readable** - JSON format is interpretable

### **Limitations**:
- üêç **Python-only** (requires custom reconstruction code)
- üîÑ **Setup overhead** - need to reconstruct classifier object

---

## **Method 3: Generated Code Rules** ‚ö°

### **Best For**: Cross-platform deployment, maximum performance
### **Format**: Native code files (.py, .java, .cpp)

```bash
# Generate rule code in multiple languages
./venv/bin/python tools/generate_rule_code.py \
    --input my_model.json \
    --languages python,java,cpp \
    --output generated_rules/ \
    --optimize_order \
    --include_stats
```

### **Generated Python Code**:
```python
# generated_rules/decision_rules.py
def predict_sample(features):
    """
    Generated decision rules for classification
    Features should be dict with binary values (0/1)
    """

    # Rule 1: High-confidence negative (99.0% confidence, 697 samples)
    if (features.get('pickUpHourOfDay=VERYLATE', 0) == 0 and
        features.get('zone_demand_popularity=POPULARITY_INDEX_5', 0) == 0 and
        features.get('sla=Immediate', 0) == 1):
        return {'prediction': 0, 'confidence': 0.990, 'rule_id': 1, 'samples': 697}

    # Rule 2: Medium-confidence positive (74.4% confidence, 996 samples)
    if (features.get('pickUpHourOfDay=VERYLATE', 0) == 1 and
        features.get('city=Delhi NCR', 0) == 0 and
        features.get('dayType=WEEKEND', 0) == 1):
        return {'prediction': 1, 'confidence': 0.744, 'rule_id': 2, 'samples': 996}

    # ... more rules ...

    # Default fallback
    return {'prediction': 0, 'confidence': 0.500, 'rule_id': -1, 'samples': 0}

# Usage
sample_features = {
    'pickUpHourOfDay=VERYLATE': 0,
    'zone_demand_popularity=POPULARITY_INDEX_5': 0,
    'sla=Immediate': 1,
    'city=Delhi NCR': 1
}

result = predict_sample(sample_features)
print(f"Prediction: {result['prediction']}, Confidence: {result['confidence']:.3f}")
```

### **Generated Java Code**:
```java
// generated_rules/DecisionRules.java
public class DecisionRules {
    public record PredictionResult(int prediction, double confidence, int ruleId, int samples) {}

    public static PredictionResult predict(Map<String, Integer> features) {
        // Rule 1: High-confidence negative
        if (features.getOrDefault("pickUpHourOfDay=VERYLATE", 0) == 0 &&
            features.getOrDefault("zone_demand_popularity=POPULARITY_INDEX_5", 0) == 0 &&
            features.getOrDefault("sla=Immediate", 0) == 1) {
            return new PredictionResult(0, 0.990, 1, 697);
        }

        // Rule 2: Medium-confidence positive
        if (features.getOrDefault("pickUpHourOfDay=VERYLATE", 0) == 1 &&
            features.getOrDefault("city=Delhi NCR", 0) == 0 &&
            features.getOrDefault("dayType=WEEKEND", 0) == 1) {
            return new PredictionResult(1, 0.744, 2, 996);
        }

        // Default
        return new PredictionResult(0, 0.500, -1, 0);
    }
}

// Usage
Map<String, Integer> features = Map.of(
    "pickUpHourOfDay=VERYLATE", 0,
    "sla=Immediate", 1
);
var result = DecisionRules.predict(features);
System.out.println("Prediction: " + result.prediction() + ", Confidence: " + result.confidence());
```

### **Generated C++ Code**:
```cpp
// generated_rules/decision_rules.cpp
#include <unordered_map>
#include <string>

struct PredictionResult {
    int prediction;
    double confidence;
    int rule_id;
    int samples;
};

inline int get_feature(const std::unordered_map<std::string, int>& features, const std::string& name) {
    auto it = features.find(name);
    return (it != features.end()) ? it->second : 0;
}

PredictionResult predict(const std::unordered_map<std::string, int>& features) {
    // Rule 1: High-confidence negative
    if (get_feature(features, "pickUpHourOfDay=VERYLATE") == 0 &&
        get_feature(features, "zone_demand_popularity=POPULARITY_INDEX_5") == 0 &&
        get_feature(features, "sla=Immediate") == 1) {
        return {0, 0.990, 1, 697};
    }

    // Rule 2: Medium-confidence positive
    if (get_feature(features, "pickUpHourOfDay=VERYLATE") == 1 &&
        get_feature(features, "city=Delhi NCR") == 0 &&
        get_feature(features, "dayType=WEEKEND") == 1) {
        return {1, 0.744, 2, 996};
    }

    // Default
    return {0, 0.500, -1, 0};
}
```

### **Advantages**:
- üåê **Universal compatibility** - works in any language
- ‚ö° **Extreme performance** - compiled rules, no tree traversal
- üì¶ **Zero dependencies** - pure conditional logic
- üîç **Auditable** - business users can read the rules
- üöÄ **Production ready** - deploy anywhere

### **Limitations**:
- üìù **Code generation step** - requires build process
- üìè **Large trees** - many rules can create large files

---

## **Method 4: SQL Database Rules** üóÑÔ∏è

### **Best For**: Data warehouses, database-centric systems
### **Format**: SQL (.sql) files

```bash
# Extract SQL validation queries
./venv/bin/python tools/extract_tree_rules.py \
    my_model.json \
    --save_sql validation_queries.sql \
    --table my_data_table \
    --target_column outcome \
    --quiet
```

### **Generated SQL**:
```sql
-- Generated decision rules as SQL queries
-- Rule 1: High-confidence negative (99.0% confidence, 697 samples)
SELECT 'Rule_1' as rule_id, 0 as prediction, 0.990 as confidence, COUNT(*) as actual_samples,
       AVG(CASE WHEN outcome = 1 THEN 1.0 ELSE 0.0 END) as actual_positive_rate
FROM my_data_table
WHERE `pickUpHourOfDay=VERYLATE` = 0
  AND `zone_demand_popularity=POPULARITY_INDEX_5` = 0
  AND `sla=Immediate` = 1;
-- Expected: actual_samples ‚âà 697, actual_positive_rate ‚âà 0.010

-- Rule 2: Medium-confidence positive (74.4% confidence, 996 samples)
SELECT 'Rule_2' as rule_id, 1 as prediction, 0.744 as confidence, COUNT(*) as actual_samples,
       AVG(CASE WHEN outcome = 1 THEN 1.0 ELSE 0.0 END) as actual_positive_rate
FROM my_data_table
WHERE `pickUpHourOfDay=VERYLATE` = 1
  AND `city=Delhi NCR` = 0
  AND `dayType=WEEKEND` = 1;
-- Expected: actual_samples ‚âà 996, actual_positive_rate ‚âà 0.256

-- Prediction function (PostgreSQL/MySQL)
DELIMITER //
CREATE FUNCTION predict_outcome(
    p_pickUpHourOfDay_VERYLATE INT,
    p_zone_demand_popularity_INDEX_5 INT,
    p_sla_Immediate INT,
    p_city_Delhi_NCR INT,
    p_dayType_WEEKEND INT
) RETURNS JSON
READS SQL DATA
BEGIN
    -- Rule 1
    IF (p_pickUpHourOfDay_VERYLATE = 0 AND
        p_zone_demand_popularity_INDEX_5 = 0 AND
        p_sla_Immediate = 1) THEN
        RETURN JSON_OBJECT('prediction', 0, 'confidence', 0.990, 'rule_id', 1);
    END IF;

    -- Rule 2
    IF (p_pickUpHourOfDay_VERYLATE = 1 AND
        p_city_Delhi_NCR = 0 AND
        p_dayType_WEEKEND = 1) THEN
        RETURN JSON_OBJECT('prediction', 1, 'confidence', 0.744, 'rule_id', 2);
    END IF;

    -- Default
    RETURN JSON_OBJECT('prediction', 0, 'confidence', 0.500, 'rule_id', -1);
END //
DELIMITER ;

-- Usage
SELECT predict_outcome(0, 0, 1, 1, 0) as prediction;
```

### **Advantages**:
- üóÑÔ∏è **Native database integration** - runs where your data lives
- üìä **Batch scoring** - score millions of rows efficiently
- ‚úÖ **Validation built-in** - compare predicted vs actual statistics
- üîí **Security** - leverage database permissions and auditing

### **Limitations**:
- üóÑÔ∏è **Database-specific** - syntax varies between SQL dialects
- ‚ö° **Performance varies** - depends on database optimization

---

## **Method 5: REST API Service** üåê

### **Best For**: Microservice architecture, language-agnostic access
### **Format**: HTTP service

```python
# api_service.py - Flask/FastAPI wrapper
from flask import Flask, request, jsonify
from theta_sketch_tree import ThetaSketchDecisionTreeClassifier
import numpy as np

app = Flask(__name__)
model = ThetaSketchDecisionTreeClassifier.load_model('my_model.pkl')

@app.route('/predict', methods=['POST'])
def predict():
    try:
        # Expect JSON with features array
        data = request.get_json()
        features = np.array([data['features']])

        prediction = model.predict(features)[0]
        probability = model.predict_proba(features)[0]

        return jsonify({
            'prediction': int(prediction),
            'probability': {
                'negative': float(probability[0]),
                'positive': float(probability[1])
            },
            'confidence': float(max(probability))
        })

    except Exception as e:
        return jsonify({'error': str(e)}), 400

@app.route('/predict_batch', methods=['POST'])
def predict_batch():
    try:
        data = request.get_json()
        features = np.array(data['features'])  # Array of feature arrays

        predictions = model.predict(features)
        probabilities = model.predict_proba(features)

        results = []
        for i, (pred, prob) in enumerate(zip(predictions, probabilities)):
            results.append({
                'index': i,
                'prediction': int(pred),
                'probability': {
                    'negative': float(prob[0]),
                    'positive': float(prob[1])
                },
                'confidence': float(max(prob))
            })

        return jsonify({'results': results})

    except Exception as e:
        return jsonify({'error': str(e)}), 400

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
```

### **Usage from Any Language**:

```bash
# cURL
curl -X POST http://localhost:5000/predict \
  -H "Content-Type: application/json" \
  -d '{"features": [1, 0, 1, 0, 1]}'

# Response: {"prediction": 1, "probability": {"negative": 0.25, "positive": 0.75}, "confidence": 0.75}
```

```javascript
// JavaScript/Node.js
const response = await fetch('http://localhost:5000/predict', {
  method: 'POST',
  headers: {'Content-Type': 'application/json'},
  body: JSON.stringify({features: [1, 0, 1, 0, 1]})
});
const result = await response.json();
console.log('Prediction:', result.prediction, 'Confidence:', result.confidence);
```

```java
// Java
import java.net.http.*;
HttpClient client = HttpClient.newHttpClient();
HttpRequest request = HttpRequest.newBuilder()
    .uri(URI.create("http://localhost:5000/predict"))
    .header("Content-Type", "application/json")
    .POST(HttpRequest.BodyPublishers.ofString("{\"features\": [1, 0, 1, 0, 1]}"))
    .build();

HttpResponse<String> response = client.send(request, HttpResponse.BodyHandlers.ofString());
System.out.println(response.body());
```

### **Advantages**:
- üåê **Language agnostic** - any language that can make HTTP calls
- üîÑ **Centralized** - single model serves multiple applications
- üìä **Monitoring** - built-in logging, metrics, A/B testing
- üîß **Scalable** - load balancing, auto-scaling

### **Limitations**:
- üåê **Network overhead** - latency for each prediction
- üèóÔ∏è **Infrastructure** - requires service deployment and management

---

## **Method 6: ONNX Export** üîÑ

### **Best For**: ML deployment platforms, edge computing
### **Format**: ONNX (.onnx) files

```python
# export_to_onnx.py - Convert tree rules to ONNX format
import onnx
import numpy as np
from skl2onnx import convert_sklearn
from sklearn.tree import DecisionTreeClassifier

def export_theta_tree_to_onnx(model_json_path, output_onnx_path):
    """
    Export theta sketch tree as ONNX model by converting rules to sklearn tree
    """
    # Load tree rules
    with open(model_json_path, 'r') as f:
        model_data = json.load(f)

    # Extract decision paths and convert to sklearn-compatible format
    # This requires implementing rule extraction and sklearn tree construction
    # ... implementation details ...

    # Convert to ONNX
    onnx_model = convert_sklearn(
        sklearn_tree,
        initial_types=[('features', FloatTensorType([None, n_features]))],
        target_opset=11
    )

    # Save ONNX model
    with open(output_onnx_path, 'wb') as f:
        f.write(onnx_model.SerializeToString())

# Usage
export_theta_tree_to_onnx('my_model.json', 'my_model.onnx')
```

### **Using ONNX Model**:
```python
import onnxruntime as rt

# Load ONNX model
sess = rt.InferenceSession('my_model.onnx')

# Make predictions
input_name = sess.get_inputs()[0].name
pred_onx = sess.run(None, {input_name: features.astype(np.float32)})
```

### **Advantages**:
- üîÑ **Cross-platform** - runs on any ONNX-compatible runtime
- ‚ö° **Optimized** - hardware acceleration (GPU, TPU, etc.)
- üì± **Edge deployment** - mobile, IoT, embedded systems
- üè≠ **ML platforms** - integrates with MLflow, Kubeflow, etc.

### **Limitations**:
- üîß **Complex export** - requires converting rules to ONNX operations
- üìè **Format constraints** - ONNX may not support all tree features

---

## üöÄ **Performance Comparison**

| Method | Latency (single) | Throughput (batch) | Memory Usage | Setup Complexity |
|--------|------------------|-------------------|--------------|------------------|
| **Direct Python** | ~2.5Œºs | >400K/sec | Medium | ‚≠ê Simple |
| **JSON Reconstruction** | ~3.0Œºs | >300K/sec | Medium | ‚≠ê‚≠ê Moderate |
| **Generated Rules** | ~0.5Œºs | >2M/sec | Low | ‚≠ê‚≠ê‚≠ê Complex |
| **SQL Rules** | ~100Œºs | >1M/sec (batch) | Low | ‚≠ê‚≠ê Moderate |
| **REST API** | ~5ms | Variable | Medium | ‚≠ê‚≠ê‚≠ê Complex |
| **ONNX** | ~1Œºs | >1M/sec | Low | ‚≠ê‚≠ê‚≠ê‚≠ê Very Complex |

---

## üéØ **Recommendation Matrix**

### **Choose Direct Python If**:
- ‚úÖ Python-only environment
- ‚úÖ Need full model features (importance, inspection)
- ‚úÖ Simple integration requirements
- ‚úÖ Moderate performance needs

### **Choose Generated Rules If**:
- ‚úÖ Cross-platform deployment needed
- ‚úÖ Maximum performance required
- ‚úÖ Zero-dependency deployment
- ‚úÖ Business rule transparency important

### **Choose SQL Rules If**:
- ‚úÖ Data warehouse environment
- ‚úÖ Batch scoring requirements
- ‚úÖ Data already in database
- ‚úÖ SQL-based analytics team

### **Choose REST API If**:
- ‚úÖ Microservice architecture
- ‚úÖ Multiple languages/teams
- ‚úÖ Centralized model management
- ‚úÖ A/B testing requirements

### **Choose ONNX If**:
- ‚úÖ Edge/mobile deployment
- ‚úÖ Hardware acceleration needed
- ‚úÖ ML platform integration
- ‚úÖ Maximum portability required

---

## üîß **Quick Start Scripts**

```bash
# Generate all formats from trained model
./tools/export_all_formats.sh my_model.json output_dir/

# Creates:
# - output_dir/rules.py (Python rules)
# - output_dir/Rules.java (Java rules)
# - output_dir/rules.cpp (C++ rules)
# - output_dir/rules.sql (SQL rules)
# - output_dir/api_service.py (REST API)
# - output_dir/model.onnx (ONNX export)
```

This guide covers **every possible way** to use your trained trees. Choose the method that best fits your deployment requirements!